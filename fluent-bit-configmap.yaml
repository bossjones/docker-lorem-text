# SOURCE: https://git.corp.adobe.com/adobe-platform/k8s-logging-reference/blob/master/fluent-bit-reference.yaml#L171-L355
# NOTE: This is deliberately not managed by kustomize, as we want a predictable configuration name that we can always reference in each cron manifest.
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-sidecar-config
data:
  # Recommended reading:
  # https://docs.fluentbit.io/manual/getting_started
  # https://docs.fluentbit.io/manual/configuration/variables
  # https://docs.fluentbit.io/manual/configuration/commands
  fluent-bit.conf: |
    [SERVICE]
      # https://docs.fluentbit.io/manual/configuration/file#config_section
      Flush 5
      Log_Level trace
      Daemon off
      Parsers_File parsers.conf
      # Configure metrics endpoint
      # https://docs.fluentbit.io/manual/configuration/monitoring
      HTTP_Server On
      HTTP_Listen 0.0.0.0
      HTTP_Port 2020
      # Use filesystem as buffer
      # https://docs.fluentbit.io/manual/configuration/buffering#service-section-configuration
      storage.path /var/fluent-bit/buffers
      # Each input also needs a storage.type config set
      # https://docs.fluentbit.io/manual/configuration/buffering#input-section-configuration
      Grace 10
    [INPUT]
      # Read logs from the Docker or CRI-O logging driver
      # https://git.corp.adobe.com/adobe-platform/k8s-docker-logging-driver
      # https://git.corp.adobe.com/adobe-platform/k8s-cri-logging-driver
      # https://docs.fluentbit.io/manual/input/tail
      Name tail
      Parser ${LOG_PARSER}
      # If you are using Docker and you need to parse log lines larger than
      # 16k in size, uncomment the Docker_Mode line.
      # Leave this disabled if using CRI-O
      #Docker_Mode On
      # Each container's logs will appear as a log file in /logging-volume.
      # If a container is restarted, a new log file will be created as well.
      Path /logging-volume/*.log
      # Refresh_Interval configures how often Fluent Bit will scan for new log
      # files. The default is 60 seconds; we reduce to 1 second to reduce
      # delays after container restarts.
      Refresh_Interval 1
      DB /var/fluent-bit/logs.db
      Buffer_Max_Size 50M
      storage.type filesystem
    # [FILTER]
    #   # https://docs.fluentbit.io/manual/filter/modify
    #   Name modify
    #   Match *
    #   Rename log message

    #   Add index ${SPLUNK_INDEX}
    #   Add host ${NODE_NAME}
    #   Add sourcetype ${SPLUNK_SOURCETYPE}

    #   # Fields defined here MUST be nested into the Splunk payload schema
    #   # correctly in a nest filter. If a field is added here and not nested
    #   # under the top-level event key, Splunk will reject ALL logs!!
    #   Add namespace ${POD_NAMESPACE}
    #   Add node_ip ${NODE_IP}
    #   Add node_name ${NODE_NAME}
    #   Add pod_ip ${POD_IP}
    #   Add pod_name ${POD_NAME}
    #   Add pod_uid ${POD_UID}
    # Splunk rejects empty string messages with HTTP 400 errors.
    # If your app outputs empty strings in a non-JSON format, you can uncomment
    # this section to drop these logs.
    # However, this filter will drop all JSON formatted logs.
    #[FILTER]
      # https://docs.fluentbit.io/manual/filter/grep
      #Name grep
      #Match *
      #Exclude message ^\s*$
    # [FILTER]
    #   # Move fields into the event subfield so that logs appear as structured
    #   # objects in Splunk.
    #   # https://docs.fluentbit.io/manual/filter/nest
    #   #
    #   # Note that both the log message and metadata are nested under the
    #   # top-level event key instead of the top-level fields key.
    #   # This was a deliberate decision. The content of the top-level fields key
    #   # is indexed for search while the content of the top-level event key is
    #   # not. Some of the metadata such as node_name, pod_name and pod_uid has
    #   # high cardinality. Indexing these metadata fields greatly increases load
    #   # on Splunk.
    #   Name nest
    #   Match *
    #   Operation nest
    #   # Log content
    #   Wildcard message

    #   # Sidecar fields
    #   Wildcard namespace
    #   Wildcard node_ip
    #   Wildcard node_name
    #   Wildcard pod_ip
    #   Wildcard pod_name
    #   Wildcard pod_uid
    #   Wildcard stream

    #   Nest_under event
    # [FILTER]
    #   # Only the following keys are allowed in Splunk HEC payloads:
    #   # - event
    #   # - fields
    #   # - host
    #   # - index
    #   # - source
    #   # - sourcetype
    #   # - time
    #   # We drop the time key to allow Fluent Bit to correctly format the time
    #   # key in Splunk HEC format.
    #   # All other keys _must_ be dropped, or Splunk will reject the entire
    #   # payload with an HTTP 400 error.
    #   # https://docs.splunk.com/Documentation/Splunk/8.0.0/Data/FormateventsforHTTPEventCollector
    #   # https://docs.fluentbit.io/manual/filter/record_modifier#remove-fields-with-whitelist_key
    #   Name record_modifier
    #   Match *
    #   Whitelist_key event
    #   Whitelist_key fields
    #   Whitelist_key host
    #   Whitelist_key index
    #   Whitelist_key source
    #   Whitelist_key sourcetype
    # If you need to debug a Splunk output issue, uncomment the stdout output
    # plugin section below to log the raw JSON payloads sent to Splunk.
    # https://docs.fluentbit.io/manual/output/splunk
    #[OUTPUT]
    #  Name stdout
    #  Match *
    #  Format json_lines
    # [OUTPUT]
    #   Name splunk
    #   Match *
    #   Host ${SPLUNK_HOST}
    #   Port ${SPLUNK_PORT}
    #   Splunk_Token ${SPLUNK_TOKEN}
    #   Splunk_Send_Raw On
    #   tls On
    #   # Retry_Limit sets how many times Fluent Bit will retry sending logs to
    #   # Splunk on failure
    #   Retry_Limit 10
    #   # Reuse TCP connections to avoid SNAT exhaustion
    #   # See https://fluentbit.io/announcements/v1.4.0/
    #   KeepAlive On
    [OUTPUT]
      Name   stdout
      Match  *
  parsers.conf: |
    # Parsers must be stored in a separate file
    # https://docs.fluentbit.io/manual/parser
    [PARSER]
      # Parser for Docker container logs
      # Docker logs are in JSON format. Each line is a JSON object which has
      # the following keys:
      # - time: ISO-8601 combined date and time representation
      # - stream: stdout or stderr
      # - log: Full log line from container process
      # https://docs.fluentbit.io/manual/parser/json
      Name docker
      Format json
      Time_Key time
      Time_Format %Y-%m-%dT%H:%M:%S.%L
      Time_Keep On
      Decode_Field_As json log try_next
      Decode_Field_As escaped_utf8 log
    [PARSER]
      # Parser for CRI container logs
      # Note: As of December 2019, CRI support is still experimental!
      # The CRI log format is underdocumented as of November 2019. This parser
      # is reverse engineered from Kubernetes source code. CRI logs are
      # unstructured and (appear to) follow this format:
      # <time> <stream> <tags> <log>
      # - time: ISO-8601 combined date and time representation
      # - stream: stdout or stderr
      # - tags: A colon-delimited list of log tags. Tags are a simple list of
      #   strings (i.e. not key value pairs) and there does not appear to be a
      #   documented validator for the tags. Every log has at least one tag,
      #   which is a single capital letter F, P or E:
      #   - F: Log is a full line.
      #   - P: Log is a partial line and continues on the next line of the
      #     stream.
      #   - E: Log is the ending line of a series of partials.
      #  - log: Full or partial log line from the container process.
      # https://github.com/kubernetes/kubernetes/blob/3a1c9449a956b6026f075fa3134ff92f7d55f812/pkg/kubelet/apis/cri/v1alpha1/runtime/constants.go#L39-L55
      # https://github.com/kubernetes/kubernetes/blob/v1.15.5/pkg/kubelet/kuberuntime/logs/logs.go#L129-L173
      # https://docs.fluentbit.io/manual/parser/regular_expression
      Name cri-o
      Format regex
      # This uses Rubular regex to extract the time, stream, tags and log fields.
      # A Rubuluar sandbox is available at https://rubular.com
      Regex ^(?<time>.+) (?<stream>stdout|stderr) (?<tags>[\S:]+) (?<log>.*)$
      Time_Key time
      Time_Format %Y-%m-%dT%H:%M:%S.%L
      Time_Keep On
